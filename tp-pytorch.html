<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- HTML Meta Tags -->
  <title>Malaysia-AI blog Tensor Parallelism Pytorch</title>
  <meta name="description" content="Malaysia-AI blog Tensor Parallelism Pytorch">

  <!-- Facebook Meta Tags -->
  <meta property="og:url" content="https://malaysia-ai.org/tp-pytorch">
  <meta property="og:type" content="website">
  <meta property="og:title" content="Malaysia-AI blog Tensor Parallelism Pytorch">
  <meta property="og:description" content="Malaysia-AI blog Tensor Parallelism Pytorch">
  <meta property="og:image" content="https://malaysia-ai.org/tp-pytorch.png">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta property="twitter:domain" content="malaysia-ai.org">
  <meta property="twitter:url" content="https://malaysia-ai.org/tp-pytorch">
  <meta name="twitter:title" content="Malaysia-AI blog Tensor Parallelism Pytorch">
  <meta name="twitter:description" content="Malaysia-AI blog Tensor Parallelism Pytorch">
  <meta name="twitter:image" content="https://malaysia-ai.org/tp-pytorch.png">

  <!-- Meta Tags Generated via https://www.opengraph.xyz -->

  <style>
    body {
      line-height: 1.4;
      font-size: 16px;
      padding: 0 10px;
      margin: 50px auto;
      max-width: 1000px;
    }

    #maincontent {
      max-width: 62em;
      margin: 15 auto;
    }

    pre {
      margin-top: 0px;
      white-space: break-spaces;
    }
  </style>
</head>

<body>

  <div id="maincontent" style="margin-top: 70px">
    <h2>Tensor Parallelism Pytorch</h2>
    <p>Deep learning is getting bigger especially for Language Model, and the relationship between performance vs size
      already explained in <a href="https://arxiv.org/abs/2001.08361">kaplan2020scalinglawsneurallanguage</a>,</p>
    <img src="/kaplan2020scalinglawsneurallanguage-fig1.png" width="80%">
    <p>The more compute, more data, more parameters you have, the better the performance in term of perplexity.</p>
    <p>And when GPT-3 released, which is 175B parameters, it changed the world. From the paper <a
        href="https://arxiv.org/abs/2005.14165">brown2020languagemodelsfewshotlearners</a>, basically if you scaled
      large enough the parameters with the appropriate amount of dataset, the pretrained language model able to do any
      NLP task as long you give few examples or the technical term is few-shots learner, without need to go training
      session (training session in 2024 got multiple stages such as pretraining, continue pretraining, pre-finetuning,
      mid-finetuning, post-finetuning).</p>
    <p>Now 175B is huge, the paper released at 2020, and 175B is insane even nowadays is still considered insanely
      large. GPT-3 trained on V100, mentioned in the paper section 2.3,</p>
    <img src="/kaplan2020scalinglawsneurallanguage-2.3.png" width="80%">
    <p>V100 is best for single-precision, which is 32 bit, assumed if the model saved in float32, 4 bytes, 175B * 4
      bytes ~= 652 GB!</p>
    <p>For V100, the biggest GPU memory is 32GB, 652GB / 32 = 21 GPUs! So you need at least 21 units of V100 32GB VRAM
      just to store the model in the memory, not yet feed-forward!</p>
    <p>So how does OpenAI able to load the model into multiple-GPUs? <b>Tensor Parallelism!</b></p>
    <p>As you can see, the model is not fit in a single GPU, so we have to shard the model. There are 2 sharding method
      for deep learning, 1. Tensor Parallelism, 2. Pipeline Parallelism.</p>
    <p>Assumed I have a model with 2 hidden layers, 4x4 and 4x2, and 2 GPUs,</p>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 800 300">
      <!-- Tensor Parallelism -->
      <g transform="translate(0, 0)">
        <text x="200" y="30" font-size="16" font-weight="bold">Tensor Parallelism (2 GPUs)</text>

        <!-- Input -->
        <rect x="50" y="50" width="60" height="40" fill="#ADD8E6" stroke="black" />
        <text x="80" y="75" font-size="12" text-anchor="middle">Input</text>
        <text x="80" y="85" font-size="10" text-anchor="middle">1x4</text>

        <!-- First Linear Layer -->
        <rect x="150" y="50" width="120" height="40" fill="#90EE90" stroke="black" />
        <text x="210" y="75" font-size="12" text-anchor="middle">Linear 4x4</text>
        <line x1="210" y1="50" x2="210" y2="90" stroke="black" stroke-dasharray="5,5" />
        <text x="175" y="105" font-size="10" text-anchor="end">GPU 0</text>
        <text x="245" y="105" font-size="10" text-anchor="start">GPU 1</text>

        <!-- Second Linear Layer -->
        <rect x="310" y="50" width="120" height="40" fill="#FFA07A" stroke="black" />
        <text x="370" y="75" font-size="12" text-anchor="middle">Linear 4x2</text>
        <line x1="370" y1="50" x2="370" y2="90" stroke="black" stroke-dasharray="5,5" />
        <text x="335" y="105" font-size="10" text-anchor="end">GPU 0</text>
        <text x="405" y="105" font-size="10" text-anchor="start">GPU 1</text>

        <!-- Output -->
        <rect x="470" y="50" width="60" height="40" fill="#FFD700" stroke="black" />
        <text x="500" y="75" font-size="12" text-anchor="middle">Output</text>
        <text x="500" y="85" font-size="10" text-anchor="middle">4x1</text>

        <!-- Connections -->
        <line x1="110" y1="70" x2="150" y2="70" stroke="black" marker-end="url(#arrowhead)" />
        <line x1="270" y1="70" x2="310" y2="70" stroke="black" marker-end="url(#arrowhead)" />
        <line x1="430" y1="70" x2="470" y2="70" stroke="black" marker-end="url(#arrowhead)" />
      </g>

      <!-- Pipeline Parallelism -->
      <g transform="translate(0, 150)">
        <text x="200" y="30" font-size="16" font-weight="bold">Pipeline Parallelism (2 GPUs)</text>

        <!-- GPU 0 -->
        <rect x="50" y="50" width="240" height="80" fill="#E6E6FA" stroke="black" />
        <text x="170" y="70" font-size="14" text-anchor="middle">GPU 0</text>

        <!-- Input -->
        <rect x="70" y="80" width="60" height="40" fill="#ADD8E6" stroke="black" />
        <text x="100" y="105" font-size="12" text-anchor="middle">Input</text>
        <text x="100" y="115" font-size="10" text-anchor="middle">1x4</text>

        <!-- First Linear Layer -->
        <rect x="160" y="80" width="110" height="40" fill="#90EE90" stroke="black" />
        <text x="215" y="105" font-size="12" text-anchor="middle">Linear 4x4</text>

        <!-- GPU 1 -->
        <rect x="330" y="50" width="240" height="80" fill="#FFE4E1" stroke="black" />
        <text x="450" y="70" font-size="14" text-anchor="middle">GPU 1</text>

        <!-- Second Linear Layer -->
        <rect x="350" y="80" width="110" height="40" fill="#FFA07A" stroke="black" />
        <text x="405" y="105" font-size="12" text-anchor="middle">Linear 4x2</text>

        <!-- Output -->
        <rect x="490" y="80" width="60" height="40" fill="#FFD700" stroke="black" />
        <text x="520" y="105" font-size="12" text-anchor="middle">Output</text>
        <text x="520" y="115" font-size="10" text-anchor="middle">4x1</text>

        <!-- Connections -->
        <line x1="130" y1="100" x2="160" y2="100" stroke="black" marker-end="url(#arrowhead)" />
        <line x1="270" y1="100" x2="350" y2="100" stroke="black" marker-end="url(#arrowhead)" />
        <line x1="460" y1="100" x2="490" y2="100" stroke="black" marker-end="url(#arrowhead)" />
      </g>

      <!-- Arrowhead definition -->
      <defs>
        <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
          <polygon points="0 0, 10 3.5, 0 7" />
        </marker>
      </defs>
    </svg>
    <p>- Tensor Parallelism shard hidden layers into multiple-GPUs but all the GPUs got all the hidden layers.</p>
    <p>-- i. For the first hidden layer, we will split 4x4 into two row-wise and each GPUs store the weights, 2x4
      GPU0
      and
      2x4 GPU1.</p>
    <p>-- ii. For the second hidden layer, we will split 4x2 into two row-wise and each GPUs store the weights, 2x2
      GPU0
      and
      2x2 GPU1.</p>
    <p>-- iii. Input is 1x4 -> split into two column-wise and scatter to GPUs, 1x2 to GPU0 and 1x2 to GPU1, and each
      GPUs
      will do matmul, GPU0 1x2 matmul 2x4 = 1x4, GPU01 1x2 matmul 2x4 = 1x4, after that aggregation. In term of matmul
      coordinate,</p>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 800 650">
      <!-- Input Matrix -->
      <g transform="translate(50, 50)">
        <text x="0" y="-10" font-size="14" font-weight="bold">Input Matrix (1x4)</text>
        <rect x="0" y="0" width="200" height="50" fill="#ADD8E6" stroke="black" />
        <line x1="100" y1="0" x2="100" y2="50" stroke="black" stroke-dasharray="5,5" />
        <text x="50" y="30" text-anchor="middle" font-size="12">[a, b]</text>
        <text x="150" y="30" text-anchor="middle" font-size="12">[c, d]</text>
        <text x="-10" y="25" text-anchor="end" font-size="12">GPU 0</text>
        <text x="210" y="25" text-anchor="start" font-size="12">GPU 1</text>
      </g>

      <!-- Hidden Layer Matrix -->
      <g transform="translate(400, 50)">
        <text x="0" y="-10" font-size="14" font-weight="bold">Hidden Layer (4x4)</text>
        <rect x="0" y="0" width="200" height="200" fill="#90EE90" stroke="black" />
        <line x1="0" y1="100" x2="200" y2="100" stroke="black" stroke-dasharray="5,5" />
        <text x="100" y="50" text-anchor="middle" font-size="12">[w11, w12, w13, w14]</text>
        <text x="100" y="80" text-anchor="middle" font-size="12">[w21, w22, w23, w24]</text>
        <text x="100" y="130" text-anchor="middle" font-size="12">[w31, w32, w33, w34]</text>
        <text x="100" y="160" text-anchor="middle" font-size="12">[w41, w42, w43, w44]</text>
        <text x="-10" y="50" text-anchor="end" font-size="12">GPU 0</text>
        <text x="-10" y="150" text-anchor="end" font-size="12">GPU 1</text>
      </g>

      <!-- Matrix Multiplication -->
      <g transform="translate(50, 300)">
        <text x="0" y="-30" font-size="14" font-weight="bold">Matrix Multiplication</text>

        <!-- GPU 0 -->
        <rect x="0" y="0" width="100" height="50" fill="#ADD8E6" stroke="black" opacity="0.7" />
        <text x="50" y="30" text-anchor="middle" font-size="12">[a, b]</text>
        <rect x="120" y="0" width="200" height="100" fill="#90EE90" stroke="black" opacity="0.7" />
        <text x="220" y="30" text-anchor="middle" font-size="12">[w11, w12, w13, w14]</text>
        <text x="220" y="70" text-anchor="middle" font-size="12">[w21, w22, w23, w24]</text>
        <text x="110" y="55" text-anchor="end" font-size="12">×</text>
        <path d="M 320,50 L 340,50 L 350,60 L 360,50 L 380,50" fill="none" stroke="black" />
        <rect x="380" y="25" width="200" height="50" fill="#FFD700" stroke="black" />
        <text x="480" y="55" text-anchor="middle" font-size="12">[aw11+bw21, aw12+bw22, aw13+bw23, aw14+bw24]</text>
        <text x="0" y="-10" font-size="12" font-weight="bold">GPU 0</text>

        <!-- GPU 1 -->
        <g transform="translate(0, 120)">
          <rect x="0" y="0" width="100" height="50" fill="#ADD8E6" stroke="black" opacity="0.7" />
          <text x="50" y="30" text-anchor="middle" font-size="12">[c, d]</text>
          <rect x="120" y="0" width="200" height="100" fill="#90EE90" stroke="black" opacity="0.7" />
          <text x="220" y="30" text-anchor="middle" font-size="12">[w31, w32, w33, w34]</text>
          <text x="220" y="70" text-anchor="middle" font-size="12">[w41, w42, w43, w44]</text>
          <text x="110" y="55" text-anchor="end" font-size="12">×</text>
          <path d="M 320,50 L 340,50 L 350,60 L 360,50 L 380,50" fill="none" stroke="black" />
          <rect x="380" y="25" width="200" height="50" fill="#FFD700" stroke="black" />
          <text x="480" y="55" text-anchor="middle" font-size="12">[cw31+dw41, cw32+dw42, cw33+dw43, cw34+dw44]</text>
          <text x="0" y="-10" font-size="12" font-weight="bold">GPU 1</text>
        </g>
      </g>

      <!-- Aggregation -->
      <g transform="translate(50, 550)">
        <text x="0" y="-10" font-size="14" font-weight="bold">Aggregation</text>
        <rect x="0" y="0" width="250" height="50" fill="#FFD700" stroke="black" />
        <text x="125" y="30" text-anchor="middle" font-size="12">[aw11+bw21, aw12+bw22, aw13+bw23, aw14+bw24]</text>
        <text x="265" y="30" text-anchor="middle" font-size="14">+</text>
        <rect x="280" y="0" width="250" height="50" fill="#FFD700" stroke="black" />
        <text x="405" y="30" text-anchor="middle" font-size="12">[cw31+dw41, cw32+dw42, cw33+dw43, cw34+dw44]</text>
        <path d="M 540,25 L 560,25 L 570,35 L 580,25 L 600,25" fill="none" stroke="black" />
        <rect x="600" y="0" width="100" height="50" fill="#FFA07A" stroke="black" />
        <text x="650" y="30" text-anchor="middle" font-size="12">[o1, o2, o3, o4]</text>
        <text x="650" y="70" text-anchor="middle" font-size="12">Final Result</text>
      </g>


    </svg>
    <p>- While Pipeline Parallelism split the hidden layers into multiple-GPUs.</p>
    <p>Each technique got their own pros and cons, but this blog we will look into Tensor Parallelism using PyTorch.</p>


    <p>---</p>
    <p>thats all, give some love to <a href="https://x.com/aisyahhhrzk" target="_blank">Aisyah Razak.</a></p>
  </div>
</body>

</html>